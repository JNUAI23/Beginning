# 10/6 - 10/14
## To DO
- [ ] 阅读 VIT（everyone）
- [ ] 萌新阅读一下[入坑指北](https://github.com/JNUAI23/Beginning/blob/main/README.md)，可以JNUAI23 随便逛逛
- [ ] 对于已经有方向/进组的同学，准备一下分享你的进度（或者说值得分享的地方）


PS：
沐神论文精讲  



| 日期 | 标题 | 封面 | 时长 | 视频（播放数） |
| --: | -- | -- | --: | -- |
| 11/29/21 | [ViT](https://arxiv.org/pdf/2010.11929.pdf) 逐段精读 | <img src="imgs/vit.jpg" width="200px"/> | 1:11:30 | [![bilibili](https://img.shields.io/badge/dynamic/json?label=views&style=social&logo=bilibili&query=data.stat.view&url=https%3A%2F%2Fapi.bilibili.com%2Fx%2Fweb-interface%2Fview%3Fbvid%3DBV15P4y137jb)](https://www.bilibili.com/video/BV15P4y137jb/) <br />[![zhihu](https://img.shields.io/badge/dynamic/json?label=views&style=social&logo=zhihu&query=video.play_count&url=https://www.zhihu.com/api/v4/zvideos/1449195245754380288)](https://www.zhihu.com/zvideo/1449195245754380288)  <br />[![](https://img.shields.io/youtube/views/FRFt3x0bO94?style=social)](https://youtu.be/FRFt3x0bO94) |

[^transformer]: 1 [斯坦福100+作者的200+页综述](https://arxiv.org/abs/2108.07258)，2 [对LayerNorm的新研究](https://arxiv.org/pdf/1911.07013.pdf)，3 [对Attention在Transformer里面作用的研究](https://arxiv.org/abs/2103.03404)


## TASK:
下下周 10/14 周一下午18:30例会，每个人准备好分享对ViT的理解（PPT，不需要很花哨，白底黑字就行了），如果时间充足是建议把论文代码复现出来的（最迟下下次例会），不会配置的群里多水水  
最迟在10/16号之前写好每个人的总结，[填写跳转](https://github.com/JNUAI23/Beginning/blob/main/02MustReading/ReadingList.md)

      
